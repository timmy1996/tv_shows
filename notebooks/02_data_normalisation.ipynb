{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef412f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from utils.data_utils import create_dimension_table, create_bridge_table, parse_flexible_date, create_date_dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bcfd47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b83f0756",
   "metadata": {},
   "source": [
    "### Data Normalization \n",
    "\n",
    "The goal of this notebook is to document the normalisation process of the data. Please scroll down to the bottom for a summary of the actions taken to this end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53dc7935",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/shows_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6078445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbaa6672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           Documentary\n",
       "1                                           Documentary\n",
       "2                                           Documentary\n",
       "3                               Documentary,Crime,Drama\n",
       "4                                   Documentary,History\n",
       "5                          Crime,Drama,Mystery,Thriller\n",
       "6                                          Comedy,Drama\n",
       "7                                                Comedy\n",
       "8             Documentary,Biography,Crime,History,Sport\n",
       "9                                           Crime,Drama\n",
       "10    Animation,Action,Adventure,Drama,Fantasy,Sci-F...\n",
       "11                                   Comedy,Drama,Music\n",
       "12                                    Documentary,Music\n",
       "13                                        Drama,Romance\n",
       "14                            Drama,Fantasy,History,War\n",
       "15                                         Comedy,Drama\n",
       "16                                 Comedy,Drama,Romance\n",
       "17                                          Documentary\n",
       "18                               Biography,Comedy,Drama\n",
       "19                                                Drama\n",
       "Name: genres, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"genres\"].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b99756c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contains comma: 2506\n",
      "Contains semicolon: 0\n",
      "\n",
      "Genres NaNs: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nContains comma: {df['genres'].str.contains(',', na=False).sum()}\")\n",
    "print(f\"Contains semicolon: {df['genres'].str.contains(';', na=False).sum()}\")\n",
    "\n",
    "print(f\"\\nGenres NaNs: {df['genres'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a7579df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unique genres: 26\n",
      "\n",
      "Unique genres:\n",
      "['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'Game-Show', 'History', 'Horror', 'Music', 'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi', 'Sport', 'Talk-Show', 'Thriller', 'Unknown', 'War', 'Western']\n"
     ]
    }
   ],
   "source": [
    "all_genres = df['genres'].dropna().str.split(',').explode().str.strip()\n",
    "print(f\"\\nTotal unique genres: {all_genres.nunique()}\")\n",
    "print(f\"\\nUnique genres:\\n{sorted(all_genres.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0012fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 26\n",
      "    genre_id   genre_name\n",
      "0          1       Action\n",
      "1          2    Adventure\n",
      "2          3    Animation\n",
      "3          4    Biography\n",
      "4          5       Comedy\n",
      "5          6        Crime\n",
      "6          7  Documentary\n",
      "7          8        Drama\n",
      "8          9       Family\n",
      "9         10      Fantasy\n",
      "10        11    Game-Show\n",
      "11        12      History\n",
      "12        13       Horror\n",
      "13        14        Music\n",
      "14        15      Musical\n",
      "15        16      Mystery\n",
      "16        17         News\n",
      "17        18   Reality-TV\n",
      "18        19      Romance\n",
      "19        20       Sci-Fi\n",
      "20        21        Sport\n",
      "21        22    Talk-Show\n",
      "22        23     Thriller\n",
      "23        24      Unknown\n",
      "24        25          War\n",
      "25        26      Western\n"
     ]
    }
   ],
   "source": [
    "dim_genres = create_dimension_table(df, 'genres')\n",
    "print(f\"Rows: {len(dim_genres)}\")\n",
    "print(dim_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc656896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contains comma: 3284\n",
      "Contains semicolon: 0\n",
      "\n",
      "Director NaNs: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nContains comma: {df['top_cast'].str.contains(',', na=False).sum()}\")\n",
    "print(f\"Contains semicolon: {df['top_cast'].str.contains(';', na=False).sum()}\")\n",
    "\n",
    "# Check for NaNs\n",
    "print(f\"\\nDirector NaNs: {df['top_cast'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "825678b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unique actors: 34890\n"
     ]
    }
   ],
   "source": [
    "all_writer = df['top_cast'].dropna().str.split(',').explode().str.strip()\n",
    "print(f\"\\nTotal unique actors: {all_writer.nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7877a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contains comma: 2641\n",
      "Contains semicolon: 0\n",
      "\n",
      "Director NaNs: 0\n",
      "\n",
      "Total unique writer: 7932\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nContains comma: {df['writer'].str.contains(',', na=False).sum()}\")\n",
    "print(f\"Contains semicolon: {df['writer'].str.contains(';', na=False).sum()}\")\n",
    "\n",
    "# Check for NaNs\n",
    "print(f\"\\nDirector NaNs: {df['writer'].isna().sum()}\")\n",
    "\n",
    "all_actors = df['writer'].dropna().str.split(',').explode().str.strip()\n",
    "print(f\"\\nTotal unique writer: {all_actors.nunique()}\")\n",
    "#print(f\"\\nUnique writer:\\n{sorted(all_actors.unique()[0:5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52af2fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_genres = create_dimension_table(df, 'genres')\n",
    "dim_writers = create_dimension_table(df, 'writer')\n",
    "dim_directors = create_dimension_table(df, 'director')\n",
    "dim_cast = create_dimension_table(df, 'top_cast')\n",
    "\n",
    "dim_creators = create_dimension_table(df, 'created_by')\n",
    "dim_creators = dim_creators.rename(columns={\"created_by_id\": \"creator_id\",\"created_by_name\": \"creator_name\"})\n",
    "\n",
    "dim_production_companies = create_dimension_table(df, 'production_companies')\n",
    "dim_production_companies = dim_production_companies.rename(columns={\"production_companie_id\": \"production_company_id\",\"production_companie_name\": \"production_company_name\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b632b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bridge tables\n",
    "bridge_genres = create_bridge_table(df, 'genres', dim_genres)\n",
    "bridge_cast = create_bridge_table(df, 'top_cast', dim_cast)\n",
    "bridge_writers = create_bridge_table(df, 'writer', dim_writers)\n",
    "bridge_directors = create_bridge_table(df, 'director', dim_directors)\n",
    "bridge_companies = create_bridge_table(df, 'production_companies', dim_production_companies, id_prefix='production_company')\n",
    "bridge_creators = create_bridge_table(df,\"created_by\",dim_creators,id_prefix=\"creator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9808a50f",
   "metadata": {},
   "source": [
    "### Release date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48aa6811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df['releaseDate'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00078889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "releaseDate\n",
       "4      191\n",
       "7       47\n",
       "10    3065\n",
       "11      11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['releaseDate'].astype(str).str.len().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7edd2295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>date_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>Sex Box</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>So You Think You Can Dance</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>The Return of Jezebel James</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>The Last Templar</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>9JKL</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>Muhammad Ali's Greatest Fight</td>\n",
       "      <td>05 Oct 2013</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>Party Girl</td>\n",
       "      <td>09 Jun 1995</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>41</td>\n",
       "      <td>21 Jul 2015</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>Barbershop</td>\n",
       "      <td>13 Sep 2002</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>The World According to Dick Cheney</td>\n",
       "      <td>18 Jan 2013</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3314 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title  releaseDate  date_length\n",
       "3267                             Sex Box         2015            4\n",
       "3252          So You Think You Can Dance         2005            4\n",
       "3263         The Return of Jezebel James         2008            4\n",
       "3260                    The Last Templar         2009            4\n",
       "3186                                9JKL         2017            4\n",
       "...                                  ...          ...          ...\n",
       "1623       Muhammad Ali's Greatest Fight  05 Oct 2013           11\n",
       "2825                          Party Girl  09 Jun 1995           11\n",
       "2472                                  41  21 Jul 2015           11\n",
       "1776                          Barbershop  13 Sep 2002           11\n",
       "2105  The World According to Dick Cheney  18 Jan 2013           11\n",
       "\n",
       "[3314 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date_length'] = df['releaseDate'].astype(str).str.len()\n",
    "\n",
    "df.sort_values('date_length')[['title', 'releaseDate', 'date_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3e49be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaT count: 0\n",
      "Date range: 1969-07-21 00:00:00 to 2025-12-27 00:00:00\n"
     ]
    }
   ],
   "source": [
    "df['releaseDate'] = df['releaseDate'].apply(parse_flexible_date)\n",
    "print(f\"NaT count: {df['releaseDate'].isna().sum()}\")\n",
    "print(f\"Date range: {df['releaseDate'].min()} to {df['releaseDate'].max()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9a1b17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop(columns=['date_length'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f72ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 20819\n"
     ]
    }
   ],
   "source": [
    "dim_date = create_date_dimension('1969-01-01', '2025-12-31')\n",
    "dim_date.to_csv('power_bi_data/dim_date.csv', index=False)\n",
    "print(f\"Rows: {len(dim_date)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ecc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fact = df.drop(columns=['genres', 'top_cast', 'writer', 'director', 'production_companies','created_by'])\n",
    "df_fact = df_fact.rename(columns={\"id\": \"show_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0217eb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>seasonCount</th>\n",
       "      <th>rating</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>tagline</th>\n",
       "      <th>metascore</th>\n",
       "      <th>metascore_count</th>\n",
       "      <th>metascore_sentiment</th>\n",
       "      <th>userscore</th>\n",
       "      <th>userscore_count</th>\n",
       "      <th>userscore_sentiment</th>\n",
       "      <th>seasonCount_was_null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000358361</td>\n",
       "      <td>Planet Earth: Blue Planet II</td>\n",
       "      <td>2017-10-29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TV-G</td>\n",
       "      <td>Airing simultaneously on AMC, BBC America, IFC...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Take a deep breath</td>\n",
       "      <td>97.0</td>\n",
       "      <td>7</td>\n",
       "      <td>Universal acclaim</td>\n",
       "      <td>82</td>\n",
       "      <td>178</td>\n",
       "      <td>Universal acclaim</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000359012</td>\n",
       "      <td>America to Me</td>\n",
       "      <td>2018-08-26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>The 10-part documentary series from Steve Jame...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9</td>\n",
       "      <td>Universal acclaim</td>\n",
       "      <td>59</td>\n",
       "      <td>75</td>\n",
       "      <td>Mixed or average</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000357720</td>\n",
       "      <td>Planet Earth II</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TV-G</td>\n",
       "      <td>Narrated by David Attenborough, the sequel to ...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>A new world revealed</td>\n",
       "      <td>96.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Universal acclaim</td>\n",
       "      <td>92</td>\n",
       "      <td>242</td>\n",
       "      <td>Universal acclaim</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                         title releaseDate  seasonCount rating  \\\n",
       "0  1000358361  Planet Earth: Blue Planet II  2017-10-29          1.0   TV-G   \n",
       "1  1000359012                 America to Me  2018-08-26          1.0  TV-14   \n",
       "2  1000357720               Planet Earth II  2016-11-06          1.0   TV-G   \n",
       "\n",
       "                                         description  duration  \\\n",
       "0  Airing simultaneously on AMC, BBC America, IFC...      50.0   \n",
       "1  The 10-part documentary series from Steve Jame...      60.0   \n",
       "2  Narrated by David Attenborough, the sequel to ...      50.0   \n",
       "\n",
       "                tagline  metascore  metascore_count metascore_sentiment  \\\n",
       "0    Take a deep breath       97.0                7   Universal acclaim   \n",
       "1                   NaN       96.0                9   Universal acclaim   \n",
       "2  A new world revealed       96.0               10   Universal acclaim   \n",
       "\n",
       "   userscore  userscore_count userscore_sentiment  seasonCount_was_null  \n",
       "0         82              178   Universal acclaim                 False  \n",
       "1         59               75    Mixed or average                 False  \n",
       "2         92              242   Universal acclaim                 False  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fact.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99f3d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 12 tables to power_bi_data/:\n",
      "  fact_shows.csv: 3314 rows\n",
      "  dim_genres.csv: 26 rows\n",
      "  dim_cast.csv: 34890 rows\n",
      "  dim_writers.csv: 7932 rows\n",
      "  dim_directors.csv: 2387 rows\n",
      "  dim_companies.csv: 6873 rows\n",
      "  dim_date.csv: 684 rows\n",
      "  bridge_genres.csv: 9044 rows\n",
      "  bridge_cast.csv: 64043 rows\n",
      "  bridge_writers.csv: 12296 rows\n",
      "  bridge_directors.csv: 5395 rows\n",
      "  bridge_companies.csv: 44088 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Export all tables\n",
    "df_fact.to_csv('power_bi_data/fact_shows.csv', index=False)\n",
    "\n",
    "# Dimensions\n",
    "dim_genres.to_csv('power_bi_data/dim_genres.csv', index=False)\n",
    "dim_cast.to_csv('power_bi_data/dim_cast.csv', index=False)\n",
    "dim_writers.to_csv('power_bi_data/dim_writers.csv', index=False)\n",
    "dim_directors.to_csv('power_bi_data/dim_directors.csv', index=False)\n",
    "dim_production_companies.to_csv('power_bi_data/dim_companies.csv', index=False)\n",
    "dim_creators.to_csv('power_bi_data/dim_creators.csv', index=False)\n",
    "dim_date.to_csv('power_bi_data/dim_date.csv', index=False)\n",
    "\n",
    "# Bridges\n",
    "bridge_genres.to_csv('power_bi_data/bridge_genres.csv', index=False)\n",
    "bridge_cast.to_csv('power_bi_data/bridge_cast.csv', index=False)\n",
    "bridge_writers.to_csv('power_bi_data/bridge_writers.csv', index=False)\n",
    "bridge_directors.to_csv('power_bi_data/bridge_directors.csv', index=False)\n",
    "bridge_companies.to_csv('power_bi_data/bridge_companies.csv', index=False)\n",
    "bridge_creators.to_csv('power_bi_data/bridge_creators.csv', index=False)\n",
    "\n",
    "print(\"Exported 12 tables to power_bi_data/:\")\n",
    "print(f\"  fact_shows.csv: {len(df_fact)} rows\")\n",
    "print(f\"  dim_genres.csv: {len(dim_genres)} rows\")\n",
    "print(f\"  dim_cast.csv: {len(dim_cast)} rows\")\n",
    "print(f\"  dim_writers.csv: {len(dim_writers)} rows\")\n",
    "print(f\"  dim_directors.csv: {len(dim_directors)} rows\")\n",
    "print(f\"  dim_companies.csv: {len(dim_production_companies)} rows\")\n",
    "print(f\"  dim_date.csv: {len(dim_date)} rows\")\n",
    "print(f\"  bridge_genres.csv: {len(bridge_genres)} rows\")\n",
    "print(f\"  bridge_cast.csv: {len(bridge_cast)} rows\")\n",
    "print(f\"  bridge_writers.csv: {len(bridge_writers)} rows\")\n",
    "print(f\"  bridge_directors.csv: {len(bridge_directors)} rows\")\n",
    "print(f\"  bridge_companies.csv: {len(bridge_companies)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ba7872",
   "metadata": {},
   "source": [
    "### Data Normalization Summary - TV Shows Dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "Normalized a flat TV shows dataset into a star schema for Power BI analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### Final Schema\n",
    "\n",
    "#### Fact Table\n",
    "\n",
    "| Table | Description | Key |\n",
    "|-------|-------------|-----|\n",
    "| fact_shows | Main TV show data with measures | show_id (PK) |\n",
    "\n",
    "**Columns retained:**\n",
    "- id, title, releaseDate, seasonCount, duration\n",
    "- metascore, userscore, userscore_count\n",
    "- rating, userscore_sentiment, metascore_sentiment\n",
    "- tagline, description\n",
    "- seasonCount_was_null (flag)\n",
    "\n",
    "---\n",
    "\n",
    "#### Dimension Tables\n",
    "\n",
    "| Table | Columns | Rows |\n",
    "|-------|---------|------|\n",
    "| dim_genres | genre_id, genre_name | 26 |\n",
    "| dim_cast | cast_id, cast_name |34890 |\n",
    "| dim_writers | writer_id, writer_name | 7932 |\n",
    "| dim_directors | director_id, director_name | 2387 |\n",
    "| dim_companies | company_id, company_name | 6873   |\n",
    "| dim_creators | creator_id, creator_name | 1935 |\n",
    "| dim_date | date, year, month, month_name, year_month | ~20,800 |\n",
    "\n",
    "---\n",
    "\n",
    "#### Bridge Tables (Many-to-Many)\n",
    "\n",
    "| Table | Columns |\n",
    "|-------|---------|\n",
    "| bridge_genres | show_id, genre_id |\n",
    "| bridge_cast | show_id, cast_id |\n",
    "| bridge_writers | show_id, writer_id |\n",
    "| bridge_directors | show_id, director_id |\n",
    "| bridge_companies | show_id, company_id |\n",
    "\n",
    "---\n",
    "\n",
    "### Reusable Functions Created\n",
    "\n",
    "#### create_dimension_table()\n",
    "\n",
    "```python\n",
    "def create_dimension_table(df, column_name, id_prefix=None, delimiter=','):\n",
    "    \"\"\"\n",
    "    Create a dimension table from a multi-value column.\n",
    "    Returns DataFrame with {prefix}_id and {prefix}_name columns.\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "#### create_bridge_table()\n",
    "\n",
    "```python\n",
    "def create_bridge_table(df, column_name, dim_df, show_id_col='id', id_prefix=None, delimiter=','):\n",
    "    \"\"\"\n",
    "    Create a bridge table linking shows to a dimension.\n",
    "    Returns DataFrame with show_id and {prefix}_id columns.\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "#### create_date_dimension()\n",
    "\n",
    "```python\n",
    "def create_date_dimension(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Create a daily date dimension table.\n",
    "    Returns DataFrame with date, year, month, month_name, year_month.\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Date Handling\n",
    "\n",
    "#### Issue\n",
    "releaseDate had 4 different formats:\n",
    "- Length 4: `2004` (year only)\n",
    "- Length 7: `2004-06` (year-month)\n",
    "- Length 10: `2004-06-05` (full date)\n",
    "- Length 11: `04 Aug 2014` (OMDB format)\n",
    "\n",
    "#### Solution\n",
    "\n",
    "```python\n",
    "def parse_flexible_date(date_str):\n",
    "    \"\"\"\n",
    "    Parse dates in various formats, defaulting to first of month/year.\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "- Year only → `YYYY-01-01`\n",
    "- Year-month → `YYYY-MM-01`\n",
    "- Full date → preserved\n",
    "- OMDB format → parsed with `%d %b %Y`\n",
    "\n",
    "#### Date Range\n",
    "1969-07-21 to 2025-12-27\n",
    "\n",
    "---\n",
    "\n",
    "### Power BI Relationships\n",
    "\n",
    "```\n",
    "fact_shows.id ──────┬──> bridge_genres.show_id\n",
    "                    ├──> bridge_cast.show_id\n",
    "                    ├──> bridge_writers.show_id\n",
    "                    ├──> bridge_directors.show_id\n",
    "                    └──> bridge_companies.show_id\n",
    "\n",
    "bridge_genres.genre_id ────> dim_genres.genre_id\n",
    "bridge_cast.cast_id ───────> dim_cast.cast_id\n",
    "bridge_writers.writer_id ──> dim_writers.writer_id\n",
    "bridge_directors.director_id -> dim_directors.director_id\n",
    "bridge_companies.company_id -> dim_companies.company_id\n",
    "\n",
    "fact_shows.releaseDate ────> dim_date.date\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Export Location\n",
    "\n",
    "All files exported to `power_bi_data/` folder:\n",
    "- fact_shows.csv\n",
    "- dim_genres.csv\n",
    "- dim_cast.csv\n",
    "- dim_writers.csv\n",
    "- dim_directors.csv\n",
    "- dim_companies.csv\n",
    "- dim_date.csv\n",
    "- bridge_genres.csv\n",
    "- bridge_cast.csv\n",
    "- bridge_writers.csv\n",
    "- bridge_directors.csv\n",
    "- bridge_companies.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eadf0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_tv_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
